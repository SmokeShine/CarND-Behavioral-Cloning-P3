{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten,Dropout\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.layers import Input, Lambda,Flatten,Dense,LeakyReLU\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateek/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/utils/fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "# from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "from keras.layers import Cropping2D\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pdb\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist=pd.read_csv('../../../Pictures/driving_log.csv',\\\n",
    "                     header=None,names=['center','left','right','steering_angle','throttle','brake','speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47595, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering_angle</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/prateek/Pictures/IMG/center_2019_06_15_1...</td>\n",
       "      <td>/home/prateek/Pictures/IMG/left_2019_06_15_15_...</td>\n",
       "      <td>/home/prateek/Pictures/IMG/right_2019_06_15_15...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/prateek/Pictures/IMG/center_2019_06_15_1...</td>\n",
       "      <td>/home/prateek/Pictures/IMG/left_2019_06_15_15_...</td>\n",
       "      <td>/home/prateek/Pictures/IMG/right_2019_06_15_15...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/prateek/Pictures/IMG/center_2019_06_15_1...</td>\n",
       "      <td>/home/prateek/Pictures/IMG/left_2019_06_15_15_...</td>\n",
       "      <td>/home/prateek/Pictures/IMG/right_2019_06_15_15...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/prateek/Pictures/IMG/center_2019_06_15_1...</td>\n",
       "      <td>/home/prateek/Pictures/IMG/left_2019_06_15_15_...</td>\n",
       "      <td>/home/prateek/Pictures/IMG/right_2019_06_15_15...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/prateek/Pictures/IMG/center_2019_06_15_1...</td>\n",
       "      <td>/home/prateek/Pictures/IMG/left_2019_06_15_15_...</td>\n",
       "      <td>/home/prateek/Pictures/IMG/right_2019_06_15_15...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              center  \\\n",
       "0  /home/prateek/Pictures/IMG/center_2019_06_15_1...   \n",
       "1  /home/prateek/Pictures/IMG/center_2019_06_15_1...   \n",
       "2  /home/prateek/Pictures/IMG/center_2019_06_15_1...   \n",
       "3  /home/prateek/Pictures/IMG/center_2019_06_15_1...   \n",
       "4  /home/prateek/Pictures/IMG/center_2019_06_15_1...   \n",
       "\n",
       "                                                left  \\\n",
       "0  /home/prateek/Pictures/IMG/left_2019_06_15_15_...   \n",
       "1  /home/prateek/Pictures/IMG/left_2019_06_15_15_...   \n",
       "2  /home/prateek/Pictures/IMG/left_2019_06_15_15_...   \n",
       "3  /home/prateek/Pictures/IMG/left_2019_06_15_15_...   \n",
       "4  /home/prateek/Pictures/IMG/left_2019_06_15_15_...   \n",
       "\n",
       "                                               right  steering_angle  \\\n",
       "0  /home/prateek/Pictures/IMG/right_2019_06_15_15...             0.0   \n",
       "1  /home/prateek/Pictures/IMG/right_2019_06_15_15...             0.0   \n",
       "2  /home/prateek/Pictures/IMG/right_2019_06_15_15...             0.0   \n",
       "3  /home/prateek/Pictures/IMG/right_2019_06_15_15...             0.0   \n",
       "4  /home/prateek/Pictures/IMG/right_2019_06_15_15...             0.0   \n",
       "\n",
       "   throttle  brake     speed  \n",
       "0       0.0    0.0  0.000005  \n",
       "1       0.0    0.0  0.000001  \n",
       "2       0.0    0.0  0.000001  \n",
       "3       0.0    0.0  0.000001  \n",
       "4       0.0    0.0  0.000006  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading file in stream format\n",
    "import os\n",
    "import csv\n",
    "\n",
    "samples = []\n",
    "with open('../../../Pictures/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/prateek/Pictures/IMG/center_2019_06_15_15_40_12_134.jpg',\n",
       " '/home/prateek/Pictures/IMG/left_2019_06_15_15_40_12_134.jpg',\n",
       " '/home/prateek/Pictures/IMG/right_2019_06_15_15_40_12_134.jpg',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '5.231075E-06']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, validation_samples = train_test_split(samples, test_size=0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46643, 7)\n",
      "(952, 7)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_samples).shape)\n",
    "print(np.array(validation_samples).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            center_images=[]\n",
    "            left_images=[]\n",
    "            right_images=[]\n",
    "            \n",
    "            center_images_f=[]\n",
    "            left_images_f=[]\n",
    "            right_images_f=[]\n",
    "\n",
    "            center_angle=[]\n",
    "            left_angle=[]\n",
    "            right_angle=[]\n",
    "\n",
    "            center_angle_f=[]\n",
    "            left_angle_f=[]\n",
    "            right_angle_f=[]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples: \n",
    "                temp_c = cv2.imread(batch_sample[0])\n",
    "                angle_c = float(batch_sample[3])\n",
    "                temp_l = cv2.imread(batch_sample[1])\n",
    "                angle_l = float(batch_sample[3])+0.15\n",
    "                temp_r = cv2.imread(batch_sample[2])\n",
    "                angle_r = float(batch_sample[3])-0.15\n",
    "                \n",
    "                center_images.append(temp_c)\n",
    "                left_images.append(temp_l)\n",
    "                right_images.append(temp_r)\n",
    "\n",
    "                center_angle.append(angle_c)\n",
    "                left_angle.append(angle_l)\n",
    "                right_angle.append(angle_r)\n",
    "                #Data Augumentation\n",
    "                temp_c_f = cv2.flip(temp_c,1)\n",
    "                temp_l_f = cv2.flip(temp_l,1)\n",
    "                temp_r_f = cv2.flip(temp_r,1)\n",
    "                \n",
    "                angle_c_f = -1.0*angle_c\n",
    "                angle_l_f = -1.0*angle_l\n",
    "                angle_r_f = -1.0*angle_r\n",
    "                center_images_f.append(temp_c_f)\n",
    "                left_images_f.append(temp_l_f)\n",
    "                right_images_f.append(temp_r_f)\n",
    "\n",
    "                center_angle_f.append(angle_c_f)\n",
    "                left_angle_f.append(angle_l_f)\n",
    "                right_angle_f.append(angle_r_f)\n",
    "                \n",
    "            images=np.vstack([center_images,left_images,right_images,center_images_f,left_images_f,right_images_f])\n",
    "            angles=np.hstack([center_angle,left_angle,right_angle,center_angle_f,left_angle_f,right_angle_f])\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From nvidia paper\n",
    "https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "> The first layer of the network performs image normalization. The normalizer is hard-coded and is not\n",
    "adjusted in the learning process. Performing normalization in the network allows the normalization\n",
    "scheme to be altered with the network architecture and to be accelerated via GPU processing.\n",
    "The convolutional layers were designed to perform feature extraction and were chosen empirically\n",
    "through a series of experiments that varied layer configurations. We use strided convolutions in the\n",
    "first three convolutional layers with a 2×2 stride and a 5×5 kernel and a non-strided convolution\n",
    "with a 3×3 kernel size in the last two convolutional layers.\n",
    "We follow the five convolutional layers with three fully connected layers leading to an output control\n",
    "value which is the inverse turning radius. The fully connected layers are designed to function as a\n",
    "controller for steering, but we note that by training the system end-to-end, it is not possible to make\n",
    "a clean break between which parts of the network function primarily as feature extractor and which\n",
    "serve as controller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 65, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2112)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               211300    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 348,219\n",
      "Trainable params: 348,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3))) \n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "#The example above crops:\n",
    "\n",
    "# 70 rows pixels from the top of the image\n",
    "# 25 rows pixels from the bottom of the image\n",
    "# 0 columns of pixels from the left of the image\n",
    "# 0 columns of pixels from the right of the image\n",
    "## normalize and mean center the input \n",
    "\n",
    "\n",
    "model.add(Conv2D(24, kernel_size=(5, 5),strides=2,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv2D(36, kernel_size=(5, 5),strides=2,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv2D(48, kernel_size=(5, 5),\n",
    "                 strides=2,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "model.compile(loss = 'mse',optimizer=RMSprop(clipvalue=100),metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1458/1458 [==============================] - 144s 99ms/step - loss: 0.0186 - acc: 0.0511 - val_loss: 0.0153 - val_acc: 0.0518\n",
      "Epoch 2/3\n",
      "1458/1458 [==============================] - 139s 96ms/step - loss: 0.0163 - acc: 0.0511 - val_loss: 0.0144 - val_acc: 0.0518\n",
      "Epoch 3/3\n",
      "1458/1458 [==============================] - 140s 96ms/step - loss: 0.0152 - acc: 0.0511 - val_loss: 0.0135 - val_acc: 0.0518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f9276a320>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \\\n",
    "            steps_per_epoch=np.ceil(len(train_samples)/batch_size), \\\n",
    "            validation_data=validation_generator, \\\n",
    "            validation_steps=np.ceil(len(validation_samples)/batch_size), \\\n",
    "            epochs=3, verbose=1)\n",
    "\n",
    "# callbacks=callbacks_list,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
